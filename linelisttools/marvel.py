import os
import re
import subprocess
import typing as t
from os import getcwd
from pathlib import Path

import numpy as np
import pandas as pd

from .format import output_data


def run_marvel(
    marvel_path: t.Union[str, Path],
    marvel_trans_file: str,
    nqn: int,
    segment_file: str = None,
    min_size: int = None,
    bootstrap_iterations: int = None,
) -> None:
    transitions_path = Path(marvel_trans_file)
    transitions_folder = transitions_path.parent.absolute()
    run_command = f"{marvel_path} -t {marvel_trans_file} {'-s ' + str(segment_file) if segment_file else ''} -n {nqn}{' --minsize ' + str(min_size) if min_size is not None and min_size >= 0 else ''}{' --bootiter ' + str(bootstrap_iterations) if bootstrap_iterations is not None and bootstrap_iterations >= 0 else ''}"
    marvel_process = subprocess.Popen(
        run_command,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        cwd=transitions_folder,
    )

    marvel_process.communicate()
    # std_out_val, std_err_val = communicate_res
    # print(communicate_res)
    # print(marvel_process.returncode)
    return_code = marvel_process.returncode
    if return_code is not None and return_code != 0:
        raise RuntimeError(
            f"Marvel failed to execute correctly: Return code = {return_code}"
        )


def read_marvel_energies(
    marvel_energy_file: t.Union[str, Path], qn_list: t.List[str]
) -> pd.DataFrame:
    mvl_energy_cols = qn_list + ["energy", "unc", "degree"]
    return pd.read_csv(marvel_energy_file, delim_whitespace=True, names=mvl_energy_cols)


def generate_marvel_energies(
    marvel_path: t.Union[str, Path],
    transitions_file: str,
    qn_list: list[str],
    segment_file: str = None,
    min_size: int = None,
    bootstrap_iterations: int = None,
) -> pd.DataFrame:
    run_marvel(
        marvel_path=marvel_path,
        transitions_file=transitions_file,
        nqn=len(qn_list),
        segment_file=segment_file,
        min_size=min_size,
        bootstrap_iterations=bootstrap_iterations,
    )
    marvel_energies = read_marvel_energies(
        marvel_energy_file=(Path(getcwd()) / f"./EnergyLevels.txt").resolve(),
        qn_list=qn_list,
    )
    return marvel_energies


def parse_check_trans(
    check_trans_file: t.Union[str, Path], qn_list: t.List[str]
) -> pd.DataFrame:
    """
    Read the CheckTransitions.txt file generated by MARVEL and returns the unique set of transitions tags flagged as
    "BAD", "VERY BAD", "VAY BAD_100" or "VARY BAD_1000". Includes the input uncertainty for each bad transition and the
    current absolute energy offset from the energy level.

    Args:
        check_trans_file: The string path or Path object representing the CheckTransitions.txt file.
        qn_list:          The list of quantum numbers identifying an energy level within the MARVEL network.

    Returns:
        A DataFrame containing the tags identifying the bad transitions in the MARVEL network, their uncertainties and
            their offset from the energy levels they connect to.
    """
    check_trans_lines = []
    check_trans_regex = (
        r"^([\d\w_\-]+\.\d+)[^\S\r\n]+(\d+\.\d+)[^\S\r\n]+(\d+\.\d+)[^\S\r\n]+(\d\.\d+[eE][\-\+]\d+)[^\S\r\n]+"
        r"(-?\d\.\d+[eE][\-\+]\d+)[^\S\r\n]+"
    )
    check_trans_regex += r"([^\s]+)[^\S\r\n]+" * len(qn_list)
    check_trans_regex += r"(\d+\.\d+)[^\S\r\n]+(\d\.\d+[eE][\-\+]\d+)[^\S\r\n]+(WRONG|VERY BAD|VERY BAD_100|VERY BAD_1000)"
    print(check_trans_regex)
    check_trans_regex = re.compile(check_trans_regex)
    with open(check_trans_file, "r") as file:
        for line in list(file):
            line_match = check_trans_regex.match(line)
            if line_match is not None:
                check_trans_lines += [
                    [
                        line_match.group(1),  # Transition Tag
                        float(line_match.group(4)),  # Uncertainty
                        float(line_match.group(5)),  # Offset
                    ]
                ]

    bad_trans = pd.DataFrame(check_trans_lines, columns=["tag", "unc", "offset"])
    bad_trans["offset"] = bad_trans["offset"].abs()
    bad_trans = bad_trans.drop_duplicates(keep="first")
    bad_trans["offset_factor"] = bad_trans["offset"] / bad_trans["unc"]
    return bad_trans


def read_marvel_transitions(
    marvel_trans_file: t.Union[str, Path], qn_list: t.List[str]
) -> pd.DataFrame:
    trans_qn_columns = [qn + label for label in ("_u", "_l") for qn in qn_list]
    return pd.read_csv(
        marvel_trans_file,
        names=["energy", "unc_orig", "unc"] + trans_qn_columns + ["tag"],
        delim_whitespace=True,
    )


def optimise_bad_transitions(
    marvel_path: t.Union[str, Path],
    marvel_trans_file: t.Union[str, Path],
    segment_file: t.Union[str, Path],
    # check_trans_file: t.Union[str, Path],
    qn_list: t.List[str],
    marvel_trans_fortran_format_list: t.List[str],
    min_size: int = None,
    bootstrap_iterations: int = 100,
):
    marvel_trans = read_marvel_transitions(
        marvel_trans_file=marvel_trans_file, qn_list=qn_list
    )
    print(marvel_trans)
    iteration_num = 1
    iteration_file_name = ".".join(str(marvel_trans_file).split(".")[:-1]) + "_iter.txt"
    print(f"Iterating transitions in file {iteration_file_name}")
    check_trans_file = (
        Path(marvel_trans_file).parent / r"./CheckTransitions.txt"
    ).resolve()
    # run_marvel(
    #     marvel_path=marvel_path,
    #     marvel_trans_file=marvel_trans_file,
    #     nqn=len(qn_list),
    #     segment_file=segment_file,
    #     min_size=min_size,
    #     bootstrap_iterations=bootstrap_iterations,
    # )
    #
    # initial_bad_trans = parse_check_trans(
    #     check_trans_file=check_trans_file, qn_list=qn_list
    # )
    # num_bad_trans = len(initial_bad_trans)
    # current_bad_trans = initial_bad_trans.copy()
    num_bad_trans = 1
    current_bad_trans = None
    # TODO: Change parse_check_trans to parse_bad_transitions; add read_check_trans and set it up to check bad whether
    #  the distance in the check trans is lower than the new unc once unc has been increased, i.e.: can we lower the unc
    #  back down to minimise the increases?
    while num_bad_trans > 0:
        print(f"Iteration {iteration_num}")
        if iteration_num > 1:
            current_bad_trans["unc_new"] = current_bad_trans.apply(
                lambda x: x["unc"] + 0.01 * max(x["offset"] - x["unc"], 0), axis=1
            )
            marvel_trans = marvel_trans.merge(
                current_bad_trans[["tag", "unc_new"]], on=["tag"], how="left"
            )
            marvel_trans["unc"] = np.where(
                marvel_trans["unc_new"].isna(),
                marvel_trans["unc"],
                marvel_trans["unc_new"],
            )
            del marvel_trans["unc_new"]
            output_data(
                marvel_trans,
                filename=iteration_file_name,
                fortran_format_list=marvel_trans_fortran_format_list,
            )
        run_marvel(
            marvel_path=marvel_path,
            marvel_trans_file=iteration_file_name,
            nqn=len(qn_list),
            segment_file=segment_file,
            min_size=min_size,
            bootstrap_iterations=bootstrap_iterations,
        )
        current_bad_trans = parse_check_trans(
            check_trans_file=check_trans_file, qn_list=qn_list
        )
        num_bad_trans = len(current_bad_trans)
        iteration_num += 1
